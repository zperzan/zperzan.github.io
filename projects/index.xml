<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Zach Perzan</title>
    <link>https://zperzan.github.io/projects/</link>
      <atom:link href="https://zperzan.github.io/projects/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 25 Jul 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://zperzan.github.io/img/icon-192.png</url>
      <title>Projects</title>
      <link>https://zperzan.github.io/projects/</link>
    </image>
    
    <item>
      <title>Scraping 5-min weather data from Weather Underground</title>
      <link>https://zperzan.github.io/projects/scrape-weather-underground/</link>
      <pubDate>Sun, 25 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://zperzan.github.io/projects/scrape-weather-underground/</guid>
      <description>&lt;p&gt;Weather Undergound stores data from over 250,000 personal weather stations across the world. Unfortunately, historical data are not easy to access. It&amp;rsquo;s possible to view tables of 5-min data from a single day &amp;ndash; see &lt;a href=&#34;https://www.wunderground.com/dashboard/pws/KCOCREST39/table/2021-07-25/2021-07-25/daily&#34;&gt;this example&lt;/a&gt; from a station outside Crested Butte, Colorado &amp;ndash; but if you try to scrape the http using something like Python&amp;rsquo;s &lt;code&gt;requests&lt;/code&gt; library, the tables appear blank.&lt;/p&gt;
&lt;p&gt;Weather Underground has a security policy that blocks automated requests from viewing data stored in each table. This is where &lt;a href=&#34;https://www.selenium.dev/documentation/en/webdriver/&#34;&gt;Selenium WebDriver&lt;/a&gt; comes in. WebDriver is an toolbox for natively running web browsers, so when you render a page with WebDriver, Weather Underground thinks a regular user is accessing their website and you can access the full source code.&lt;/p&gt;
&lt;p&gt;To run the script, the first thing to do is ensure that &lt;a href=&#34;https://chromedriver.chromium.org/&#34;&gt;ChromeDriver&lt;/a&gt; is installed. Note that you have to match the ChromeDriver version to whichever version of Chrome is installed on your machine. It&amp;rsquo;s also possible to use something other than Chrome, for example &lt;a href=&#34;https://github.com/mozilla/geckodriver/releases&#34;&gt;geckodriver&lt;/a&gt; for Firefox or &lt;a href=&#34;https://webkit.org/blog/6900/webdriver-support-in-safari-10/&#34;&gt;safaridriver&lt;/a&gt; for Safari.&lt;/p&gt;
&lt;p&gt;Next, update the path to chromedriver in &lt;code&gt;scrape_wunderground.py&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Set the absolute path to chromedriver&lt;/span&gt;
chromedriver_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/path/to/chromedriver&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As long as BeautifulSoup and Selenium are installed, the script should work fine after that. However, there are a few important points to note about processing the data once it&amp;rsquo;s downloaded:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;All data is listed in local time. So summer data is in daylight savings time and winter data is in standard time.&lt;/li&gt;
&lt;li&gt;Depending on the quality of the station,&lt;/li&gt;
&lt;li&gt;All pressure data is reported as sea-level pressure. Depending on the weather station, it may be possible to back-calculate to absolute pressure; some manufacturers (e.g., Ambient Weather WS-2902) use a constant offset whereas others (e.g., Davis Vantage Pro2) perform a more complicated barometric pressure reduction using the station&amp;rsquo;s 12-hr temperature and humidity history.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The full Python script is available &lt;a href=&#34;https://zperzan.github.io/files/scrape_wunderground.py&#34;&gt;here&lt;/a&gt; but is also included below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Module to scrape 5-min personal weather station data from Weather Underground.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Usage is:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;gt;&amp;gt;&amp;gt; python scrape_wunderground.py   STATION    DATE
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;where station is a personal weather station (e.g., KCAJAMES3) and date is in the 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;format YYYY-MM-DD. 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Alternatively, each function below can be imported and used in a separate python
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;script. Note that a working version of chromedriver must be installed and the absolute 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;path to executable has to be updated below (&amp;#34;chromedriver_path&amp;#34;).
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Zach Perzan, 2021-07-28&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; bs4 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; BeautifulSoup &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; BS
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; selenium &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; webdriver


&lt;span style=&#34;color:#75715e&#34;&gt;# Set the absolute path to chromedriver&lt;/span&gt;
chromedriver_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/path/to/chromedriver&amp;#39;&lt;/span&gt;


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;render_page&lt;/span&gt;(url):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Given a url, render it with chromedriver and return the html source
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        url : str
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            url to render
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        r : 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            rendered page source
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    
    driver &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; webdriver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Chrome(chromedriver_path)
    driver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(url)
    time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sleep(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# Could potentially decrease the sleep time&lt;/span&gt;
    r &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; driver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;page_source
    driver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;quit()

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; r


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;scrape_wunderground&lt;/span&gt;(station, date):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Given a PWS station ID and date, scrape that day&amp;#39;s data from Weather 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Underground and return it as a dataframe.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        station : str
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            The personal weather station ID
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        date : str
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            The date for which to acquire data, formatted as &amp;#39;YYYY-MM-DD&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        df : dataframe or None
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            A dataframe of weather observations, with index as pd.DateTimeIndex 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            and columns as the observed data
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Render the url and open the page source as BS object&lt;/span&gt;
    url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://www.wunderground.com/dashboard/pws/&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;/table/&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;/daily&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (station,
                                                                               date, date)
    r &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; render_page(url)
    soup &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BS(r, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;html.parser&amp;#34;&lt;/span&gt;,)

    container &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; soup&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lib-history-table&amp;#39;&lt;/span&gt;)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Check that lib-history-table is found&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; container &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;raise&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ValueError&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;could not find lib-history-table in html source for &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; url)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Get the timestamps and data from two separate &amp;#39;tbody&amp;#39; tags&lt;/span&gt;
    all_checks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; container&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_all(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tbody&amp;#39;&lt;/span&gt;)
    time_check &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; all_checks[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    data_check &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; all_checks[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]

    &lt;span style=&#34;color:#75715e&#34;&gt;# Iterate through &amp;#39;tr&amp;#39; tags and get the timestamps&lt;/span&gt;
    hours &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; time_check&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_all(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tr&amp;#39;&lt;/span&gt;):
        trial &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_text()
        hours&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(trial)

    &lt;span style=&#34;color:#75715e&#34;&gt;# For data, locate both value and no-value (&amp;#34;--&amp;#34;) classes&lt;/span&gt;
    classes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;wu-value wu-value-to&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;wu-unit-no-value ng-star-inserted&amp;#39;&lt;/span&gt;]

    &lt;span style=&#34;color:#75715e&#34;&gt;# Iterate through span tags and get data&lt;/span&gt;
    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; data_check&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_all(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;span&amp;#39;&lt;/span&gt;, class_&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;classes):
        trial &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_text()
        data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(trial)

    columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Temperature&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Dew Point&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Humidity&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wind Speed&amp;#39;&lt;/span&gt;, 
               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wind Gust&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Pressure&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Precip. Rate&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Precip. Accum.&amp;#39;&lt;/span&gt;]

    &lt;span style=&#34;color:#75715e&#34;&gt;# Convert NaN values (stings of &amp;#39;--&amp;#39;) to np.nan&lt;/span&gt;
    data_nan &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nan &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; x &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; data]

    &lt;span style=&#34;color:#75715e&#34;&gt;# Convert list of data to an array&lt;/span&gt;
    data_array &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(data_nan, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;float)
    data_array &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data_array&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(columns))

    &lt;span style=&#34;color:#75715e&#34;&gt;# Prepend date to HH:MM strings&lt;/span&gt;
    timestamps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (date, t) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; t &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; hours]

    &lt;span style=&#34;color:#75715e&#34;&gt;# Convert to dataframe&lt;/span&gt;
    df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(index&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;timestamps, data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;data_array, columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;columns)
    df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_datetime(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index)
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; df


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;scrape_multiattempt&lt;/span&gt;(station, date, attempts&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, wait_time&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5.0&lt;/span&gt;):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Try to scrape data from Weather Underground. If there is an error on the 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    first attempt, try again.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        station : str
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            The personal weather station ID
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        date : str
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            The date for which to acquire data, formatted as &amp;#39;YYYY-MM-DD&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        attempts : int, default 4
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            Maximum number of times to try accessing before failuer
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        wait_time : float, default 5.0
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            Amount of time to wait in between attempts
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        df : dataframe or None
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            A dataframe of weather observations, with index as pd.DateTimeIndex 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            and columns as the observed data
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Try to download data limited number of attempts&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(attempts):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
            df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; scrape_wunderground(station, date)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt;:
            &lt;span style=&#34;color:#75715e&#34;&gt;# if unsuccessful, pause and retry&lt;/span&gt;
            time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sleep(wait_time)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;: 
            &lt;span style=&#34;color:#75715e&#34;&gt;# if successful, then break&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# If all attempts failed, return empty df&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame()
        
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; df
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Mapping lava tube caves with LiDAR</title>
      <link>https://zperzan.github.io/projects/lidar-caves/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://zperzan.github.io/projects/lidar-caves/</guid>
      <description>&lt;p&gt;In 2015, I worked for the Bureau of Land Management in Shoshone, Idaho, as part of the Geological Society of America&amp;rsquo;s GeoCorps program. Most of my time was spent driving around the desert, dodging rattlesnakes and exploring lava tube caves. In collaboration with researchers from Idaho State University, we used a tripod-mounted LiDAR system to map the interior of several caves.&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;MazeCave_Side.png&#34; &gt;

&lt;img src=&#34;MazeCave_Side.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Full map of Maze Cave, viewed from the side. A single map consists of several (20-50) different individual scans from the LiDAR unit that are then merged together during post-processing.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The BLM was interested in detailed cave maps for practical reasons &amp;ndash; in case of a rescue, for example &amp;ndash; as well as for basic research purposes. Precise cross-sections of lava tubes can be used to infer the velocity and viscocity of lava that once flowed through the caves, while a time series of LiDAR scans can be used to better understand cave wall deformation and cave collapse.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Teaching an RNN to write Movie Scripts</title>
      <link>https://zperzan.github.io/projects/script-generator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://zperzan.github.io/projects/script-generator/</guid>
      <description>&lt;p&gt;&lt;em&gt;Note: all code and data for this project can be found in a &lt;a href=&#34;https://github.com/zperzan/tarantino&#34;&gt;GitHub repository&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Around Christmas, I was home visiting family and sat through an overload of Hallmark Channel holiday movies. To me, Hallmark holiday movies all have the same plot and same characters with different names, so I joked that a well-trained neural net could easily write one and no one would know the difference.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; That joke made me wonder how hard it would be to train an RNN to write movie scripts, so I set out to try.&lt;/p&gt;
&lt;p&gt;It turns out scripts for movies on the Hallmark Channel are hard to find, so I decided to use screenplays written by Quentin Tarantino instead. I couldn&amp;rsquo;t find a usable copy of &lt;em&gt;Grindhouse: Death Proof&lt;/em&gt;, but I got vector PDFs for everything else &amp;ndash;
12 out of 13 isn&amp;rsquo;t bad.&lt;/p&gt;
&lt;p&gt;I converted the PDFs to text, cleaned up the text using a combination of &lt;code&gt;sed&lt;/code&gt; and &lt;code&gt;awk&lt;/code&gt;, embedded the characters as one-hot vectors, and fed that into a bidirectional LSTM. Words in all caps have special meaning in screenplays (names of characters, camera directions), so I embedded upper and lower case letters separately.&lt;/p&gt;
&lt;p&gt;The finished model consists of 2 bidirectional LSTM layers &amp;ndash; each with 512 nodes and 20% recurrent dropout &amp;ndash; topped off by fully-connected Softmax layer with 82 nodes (there are 82 total characters in the model). The full details and all the code is available in the &lt;a href=&#34;https://github.com/zperzan/tarantino&#34;&gt;repo&lt;/a&gt;. For now, let&amp;rsquo;s see some sample output:&lt;/p&gt;








  
  


&lt;div class=&#34;gallery&#34;&gt;

  
  
  
  

  
  
  
  
  
    
      
    
  
  &lt;a data-fancybox=&#34;gallery-gallery&#34; data-caption=&#34;Sample text generated by the model. All formatting (line length, capitalization, line breaks, etc) are from the model itself. The only alteration was to blur out specific curse words. The only change&#34; href=&#34;https://zperzan.github.io/img/TextSample6.jpg&#34;&gt;
    &lt;img src=&#34;https://zperzan.github.io/img/TextSample6.jpg&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  
  
  
  
    
      
    
  
  &lt;a data-fancybox=&#34;gallery-gallery&#34; data-caption=&#34;Sample text generated by the model. All formatting (line length, capitalization, line breaks, etc) are from the model itself. The only alteration was to blur out specific curse words.&#34; href=&#34;https://zperzan.github.io/img/TextSample5.jpg&#34;&gt;
    &lt;img src=&#34;https://zperzan.github.io/img/TextSample5.jpg&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  
  
  
  
    
      
    
  
  &lt;a data-fancybox=&#34;gallery-gallery&#34; data-caption=&#34;Sample text generated by the model. All formatting (line length, capitalization, line breaks, etc) are from the model itself. The only alteration was to blur out specific curse words.&#34; href=&#34;https://zperzan.github.io/img/TextSample9.jpg&#34;&gt;
    &lt;img src=&#34;https://zperzan.github.io/img/TextSample9.jpg&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  
  
  
  
    
      
    
  
  &lt;a data-fancybox=&#34;gallery-gallery&#34; data-caption=&#34;Sample text generated by the model. All formatting (line length, capitalization, line breaks, etc) are from the model itself. The only alteration was to blur out specific curse words.&#34; href=&#34;https://zperzan.github.io/img/TextSample2.jpg&#34;&gt;
    &lt;img src=&#34;https://zperzan.github.io/img/TextSample2.jpg&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  
  
  
  
    
      
    
  
  &lt;a data-fancybox=&#34;gallery-gallery&#34; data-caption=&#34;Sample text generated by the model. All formatting (line length, capitalization, line breaks, etc) are from the model itself. The only alteration was to blur out specific curse words.&#34; href=&#34;https://zperzan.github.io/img/TextSample7.jpg&#34;&gt;
    &lt;img src=&#34;https://zperzan.github.io/img/TextSample7.jpg&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  
  
  
  
    
      
    
  
  &lt;a data-fancybox=&#34;gallery-gallery&#34; data-caption=&#34;Sample text generated by the model. All formatting (line length, capitalization, line breaks, etc) are from the model itself. The only alteration was to blur out specific curse words.&#34; href=&#34;https://zperzan.github.io/img/TextSample8.jpg&#34;&gt;
    &lt;img src=&#34;https://zperzan.github.io/img/TextSample8.jpg&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  
  
  
  
    
      
    
  
  &lt;a data-fancybox=&#34;gallery-gallery&#34; data-caption=&#34;Sample text generated by the model. All formatting (line length, capitalization, line breaks, etc) are from the model itself. The only alteration was to blur out specific curse words.&#34; href=&#34;https://zperzan.github.io/img/TextSample3.jpg&#34;&gt;
    &lt;img src=&#34;https://zperzan.github.io/img/TextSample3.jpg&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  
  
  
  
    
      
    
  
  &lt;a data-fancybox=&#34;gallery-gallery&#34; data-caption=&#34;Sample text generated by the model. All formatting (line length, capitalization, line breaks, etc) are from the model itself. The only alteration was to blur out specific curse words.&#34; href=&#34;https://zperzan.github.io/img/TextSample4.jpg&#34;&gt;
    &lt;img src=&#34;https://zperzan.github.io/img/TextSample4.jpg&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  
  
  
&lt;/div&gt;
&lt;p&gt;A few observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The model is great at picking up on the general structure of a screenplay; characters exchange dialog and occasionally you get camera and scene instructions &amp;ndash; &amp;ldquo;CU of Mickey&amp;rdquo; (ie, a close up shot of Mickey) and &amp;ldquo;INT. - BARTHOUSE - DAY&amp;rdquo; (ie, an interior shot at the &amp;ldquo;barthouse&amp;rdquo; during the day).&lt;/li&gt;
&lt;li&gt;Scenes are an amalgam of characters from all of Tarantino&amp;rsquo;s movies (&amp;ldquo;THE BRIDE&amp;rdquo; from &lt;em&gt;Kill Bill&lt;/em&gt;, &amp;ldquo;ORDELL&amp;rdquo; from &lt;em&gt;Jackie Brown&lt;/em&gt;, etc), but unsurprisingly it doesn&amp;rsquo;t create any new character names.&lt;/li&gt;
&lt;li&gt;It&amp;rsquo;s also pretty good at word completion (short-term memory). It completes &amp;ldquo;the burn on the side of his f&amp;rdquo; with &amp;ldquo;face&amp;rdquo; and &amp;ldquo;walking towards the hos&amp;rdquo; with &amp;ldquo;hostages&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;I really like the &amp;ldquo;MAX &amp;hellip; INT. - BARTHOUSE - DAY &amp;hellip; MAX (CONT&amp;rsquo;D)&amp;rdquo; sequence, though I think that was
coincidence more than anything. With an input sequence of 50 characters, the model could not have known that MAX was talking prior to the scene change.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I didn&amp;rsquo;t fully tune the model because I felt bad wasting cluster resources on a silly task, but it achieves 60% accuracy on the test set. That&amp;rsquo;s pretty good considering the messy text and paucity of data (1.7M chars total). It trained relatively quickly as well (9 epochs with early stopping).&lt;/p&gt;
&lt;p&gt;Update 2019: I would be curious to see how well one of the &amp;ldquo;Sesame Street&amp;rdquo; models &amp;ndash; ELMo, ERNIE, BERT, XLNet, RoBERTa, Transfo-XL, GPT-2, etc &amp;ndash; would perform on the same task.
Thomas Dehaene must have had the same thought regarding Hallmark movies, as he just posted &lt;a href=&#34;https://towardsdatascience.com/an-nlp-view-on-holiday-movies-part-ii-text-generation-using-lstms-in-keras-36dc1ff8a6d2&#34;&gt;this tutorial&lt;/a&gt; on his blog. He couldn&amp;rsquo;t find any screenplays either and used subtitles instead.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;I subsequently found &lt;a href=&#34;https://twitter.com/keatonpatti/status/1072877290902745089?lang=en&#34;&gt;this post&lt;/a&gt; from a comedian making the same point, though that script was clearly human-generated.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>
